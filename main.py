# main.py
"""
Orquestrador principal do sistema C09.
Suporta dois modos de execu√ß√£o:
- CANDLES: Execu√ß√£o a cada 10min (s√≥ atualiza reports)
- COMPLETO: Execu√ß√£o a cada 1h (processamento completo + alertas)
"""

import sys
import os
import json
import traceback
from datetime import datetime, timedelta
from pathlib import Path
from io import BytesIO

# Adiciona diret√≥rios ao path para imports
sys.path.append(str(Path(__file__).parent))

from core.scraper import criar_scraper
from core.processor import criar_processor_rrp, criar_processor_tls
from config.settings import carregar_config, validar_configuracao, ConstantesEspecificas


class C09Orchestrator:
    """
    Orquestrador principal que coordena download, processamento e upload.
    Agora com suporte a execu√ß√£o cont√≠nua (CANDLES/COMPLETO).
    """
    
    def __init__(self):
        """Inicializa orquestrador com configura√ß√µes."""
        print(f"=== SISTEMA C09 INICIADO - {datetime.now():%Y-%m-%d %H:%M:%S} ===")
        
        # Carrega configura√ß√µes
        self.config = carregar_config()
        if not validar_configuracao(self.config):
            raise ValueError("Configura√ß√£o inv√°lida")
        
        self.credenciais = self.config["credenciais"]
        
        # Detecta modo de execu√ß√£o
        self.modo_execucao = self._detectar_modo_execucao()
        print(f"üîß Modo de execu√ß√£o: {self.modo_execucao}")
        
        # Inicializa componentes baseado no modo
        if self.modo_execucao == "CANDLES":
            # Modo r√°pido - n√£o precisa de scraper
            self.scraper = None
            print("‚ö° Modo CANDLES - Processamento r√°pido (4h de dados)")
        else:
            # Modo completo - inicializa scraper
            self.scraper = criar_scraper(
                chrome_driver_path=self.credenciais["chrome_driver_path"],
                download_timeout=ConstantesEspecificas.DOWNLOAD_TIMEOUT
            )
            print("üîÑ Modo COMPLETO - Processamento completo + alertas")
        
    def _detectar_modo_execucao(self) -> str:
        """
        Detecta modo de execu√ß√£o via vari√°veis de ambiente ou request body.
        
        Returns:
            "CANDLES" ou "COMPLETO"
        """
        # Verifica vari√°vel de ambiente (Cloud Run)
        modo_env = os.getenv("EXECUTION_MODE", "").upper()
        if modo_env in ["CANDLES", "COMPLETO"]:
            return modo_env
        
        # Verifica request body (Cloud Scheduler HTTP)
        try:
            request_body = os.getenv("REQUEST_BODY", "{}")
            data = json.loads(request_body)
            modo_request = data.get("mode", "").upper()
            if modo_request in ["CANDLES", "COMPLETO"]:
                return modo_request
        except:
            pass
        
        # Verifica argumentos da linha de comando
        if len(sys.argv) > 1:
            modo_args = sys.argv[1].upper()
            if modo_args in ["CANDLES", "COMPLETO"]:
                return modo_args
        
        # Default para desenvolvimento local
        return "COMPLETO"
        
    def _obter_periodo_execucao(self) -> tuple[datetime, datetime]:
        """
        Define per√≠odo de execu√ß√£o baseado no modo.
        AMBOS OS MODOS usam per√≠odo completo (01/m√™s - hoje).
        """
        hoje = datetime.now()
        
        # SEMPRE usa per√≠odo completo (01 do m√™s at√© hoje)
        data_inicial = hoje.replace(day=1)
        data_final = hoje
        
        if self.modo_execucao == "CANDLES":
            print(f"Per√≠odo CANDLES: {data_inicial.date()} at√© {data_final.date()} (completo)")
        else:
            print(f"Per√≠odo COMPLETO: {data_inicial.date()} at√© {data_final.date()}")
        
        return data_inicial, data_final
        
    def _criar_processor_para_unidade(self, unidade: str):
        """
        Cria processador espec√≠fico para a unidade.
        
        Args:
            unidade: Nome da unidade ("RRP", "TLS", etc.)
            
        Returns:
            Processador configurado para a unidade
        """
        config_pois = self.config["pois_por_unidade"][unidade]
        
        if unidade == "RRP":
            return criar_processor_rrp(config_pois)
        elif unidade == "TLS":
            return criar_processor_tls(config_pois)
        else:
            # Para novas unidades, usar processador gen√©rico
            from core.processor import C09DataProcessor
            return C09DataProcessor(config_pois)
    
    def processar_unidade_modo_candles(self, unidade_config: dict) -> bool:
        """
        Modo CANDLES: Download completo (01-hoje) + processamento + atualiza APENAS candles.
        N√ÉO executa: alertas, TPV/DM, upload arquivo principal.
        """
        unidade = unidade_config["unidade"]
        empresa_frotalog = unidade_config["empresa_frotalog"]
        
        try:
            print(f"\n‚ö° CANDLES {unidade} - Download e atualiza√ß√£o de candles")
            
            # 1. Obt√©m per√≠odo completo (01/m√™s - hoje)
            data_inicial, data_final = self._obter_periodo_execucao()
            print(f"üìÖ Per√≠odo: {data_inicial.date()} at√© {data_final.date()}")
            
            # 2. Download com per√≠odo completo (igual ao modo COMPLETO)
            print(f"üì• Baixando relat√≥rio C09...")
            caminho_relatorio = self.scraper.baixar_relatorio_c09(
                empresa_frotalog=empresa_frotalog,
                data_inicial=data_inicial,
                data_final=data_final
            )
            
            # 3. Processamento completo dos dados
            print(f"‚öôÔ∏è Processando dados...")
            processor = self._criar_processor_para_unidade(unidade)
            buffer_tratado = processor.processar_relatorio_c09(caminho_relatorio)
            
            # 4. Atualiza APENAS candles (sem alertas, sem m√©tricas pesadas)
            print(f"üìä Atualizando candles (sem alertas)...")
            sucesso_candles = self._processar_candles_sem_alertas(
                unidade=unidade,
                buffer_tratado=buffer_tratado,
                data_referencia=data_final
            )
            
            # 5. Limpeza do arquivo tempor√°rio
            self._limpar_arquivo_temporario(caminho_relatorio)
            
            if sucesso_candles:
                print(f"‚úÖ CANDLES {unidade} - Atualizados com sucesso")
                return True
            else:
                print(f"‚ö†Ô∏è CANDLES {unidade} - Falha na atualiza√ß√£o")
                return False
                
        except Exception as e:
            print(f"‚ùå ERRO CANDLES {unidade}: {e}")
            self._log_erro_detalhado(e, f"Modo CANDLES - Unidade {unidade}")
            return False
    
    def _processar_candles_sem_alertas(self, unidade: str, buffer_tratado: BytesIO, 
                                    data_referencia: datetime) -> bool:
        """
        Processa apenas candles sem sistema de alertas (vers√£o light para modo CANDLES).
        
        Args:
            unidade: Nome da unidade
            buffer_tratado: Buffer com dados processados
            data_referencia: Data de refer√™ncia
            
        Returns:
            True se processamento bem-sucedido
        """
        try:
            from core.analytics_processor import criar_analytics_processor
            
            processor_analytics = criar_analytics_processor(
                unidade=unidade,
                config=self.config
            )
            
            # Carrega dados do buffer
            df = processor_analytics.carregar_planilha_buffer(buffer_tratado)
            if df.empty:
                print("‚ö†Ô∏è Dados vazios para candles")
                return True  # N√£o √© erro, apenas sem dados novos
            
            print(f"üìä Processando candles com {len(df)} registros")
            
            # Define POIs para candles baseado na unidade
            if unidade == "RRP":
                pois_candles = ["Descarga Inocencia", "Carregamento Fabrica RRP", "PA AGUA CLARA", "Oficina JSL"]
            elif unidade == "TLS":
                pois_candles = ["PA Celulose", "Manutencao Celulose", "Carregamento Fabrica", "Descarga TAP", "Oficina Central JSL"]
            else:
                print(f"‚ö†Ô∏è Unidade {unidade} n√£o configurada para candles")
                return False
            
            # Processa candles para cada POI
            mes_atual = data_referencia.month
            ano_atual = data_referencia.year
            
            sucessos = 0
            total_eventos = 0
            
            for poi in pois_candles:
                print(f"üìà Processando candles: {poi}")
                
                # Gera candles para este POI (j√° com corre√ß√£o de sa√≠das falsas)
                df_eventos, df_resumo_hora = processor_analytics.gerar_candles_poi(df, poi)
                
                if not df_eventos.empty:
                    # Atualiza candles no SharePoint
                    sucesso = processor_analytics.reports_manager.atualizar_candles(
                        df_eventos_novos=df_eventos,
                        df_resumo_novos=df_resumo_hora,
                        poi=poi,
                        mes=mes_atual,
                        ano=ano_atual
                    )
                    
                    if sucesso:
                        sucessos += 1
                        total_eventos += len(df_eventos)
                        print(f"‚úÖ {poi}: {len(df_eventos)} eventos atualizados")
                    else:
                        print(f"‚ö†Ô∏è {poi}: Falha na atualiza√ß√£o SharePoint")
                else:
                    print(f"‚ÑπÔ∏è {poi}: Nenhum evento no per√≠odo")
                    sucessos += 1  # Sem dados √© normal, n√£o √© erro
            
            # Log final
            print(f"üìä RESUMO CANDLES: {sucessos}/{len(pois_candles)} POIs processados")
            print(f"üìà Total de eventos processados: {total_eventos}")
            
            # Considera sucesso se processou todos os POIs
            return sucessos == len(pois_candles)
            
        except ImportError as e:
            print(f"‚ùå Erro de import no processamento candles: {e}")
            return False
            
        except Exception as e:
            print(f"‚ùå Erro no processamento candles: {e}")
            return False

    def processar_unidade_modo_completo(self, unidade_config: dict) -> bool:
        """
        Processamento completo - download + processamento + alertas (modo 1h).
        
        Args:
            unidade_config: Configura√ß√£o da unidade
            
        Returns:
            True se processamento bem-sucedido
        """
        unidade = unidade_config["unidade"]
        empresa_frotalog = unidade_config["empresa_frotalog"]
        
        try:
            print(f"\n{'='*60}")
            print(f"PROCESSANDO UNIDADE: {unidade}")
            print(f"Empresa Frotalog: {empresa_frotalog}")
            print(f"{'='*60}")
            
            # 1. Obt√©m per√≠odo
            data_inicial, data_final = self._obter_periodo_execucao()
            
            # 2. Download do relat√≥rio
            print(f"\n[1/4] Baixando relat√≥rio C09...")
            caminho_relatorio = self.scraper.baixar_relatorio_c09(
                empresa_frotalog=empresa_frotalog,
                data_inicial=data_inicial,
                data_final=data_final
            )
            
            # 3. Processamento dos dados
            print(f"\n[2/4] Processando dados...")
            processor = self._criar_processor_para_unidade(unidade)
            buffer_tratado = processor.processar_relatorio_c09(caminho_relatorio)
            
            # 4. Upload para SharePoint
            print(f"\n[3/4] Enviando para SharePoint...")
            sucesso_upload = self._upload_sharepoint(
                unidade_config=unidade_config,
                data_referencia=data_final,
                buffer_tratado=buffer_tratado,
                caminho_original=caminho_relatorio
            )
            
            if not sucesso_upload:
                print(f"‚ùå Falha no upload para {unidade}")
                return False
            
            # 5. Processamento de analytics completo (com alertas)
            print(f"\n[4/4] Processamento de analytics...")
            self._processar_analytics(unidade, buffer_tratado, data_final)
            
            # 6. Limpeza
            self._limpar_arquivo_temporario(caminho_relatorio)
            
            print(f"‚úÖ Unidade {unidade} processada com sucesso!")
            return True
            
        except Exception as e:
            print(f"‚ùå ERRO ao processar unidade {unidade}: {e}")
            self._log_erro_detalhado(e, f"Modo COMPLETO - Unidade {unidade}")
            return False
    
    def _processar_analytics_tempo_real(self, unidade: str) -> bool:
        """
        Processamento de analytics em tempo real (s√≥ candles/reports).
        
        Args:
            unidade: Nome da unidade
            
        Returns:
            True se processamento bem-sucedido
        """
        try:
            from core.analytics_processor import criar_analytics_processor
            
            processor_analytics = criar_analytics_processor(
                unidade=unidade,
                config=self.config
            )
            
            # M√©todo espec√≠fico para tempo real (implementar no analytics_processor)
            sucesso = processor_analytics.processar_tempo_real(horas_periodo=4)
            
            return sucesso
            
        except ImportError as e:
            print(f"‚ùå Erro de import no analytics: {e}")
            return False
            
        except Exception as e:
            print(f"‚ùå Erro no processamento tempo real {unidade}: {e}")
            return False
    
    def _upload_sharepoint(self, unidade_config: dict, data_referencia: datetime, 
                          buffer_tratado: BytesIO, caminho_original: str) -> bool:
        """
        Faz upload dos arquivos para SharePoint.
        
        Args:
            unidade_config: Configura√ß√£o da unidade
            data_referencia: Data de refer√™ncia para nome do arquivo
            buffer_tratado: Buffer com Excel tratado
            caminho_original: Caminho do arquivo original
            
        Returns:
            True se sucesso, False caso contr√°rio
        """
        try:
            from core.sharepoint_uploader import SharePointUploader
            
            uploader = SharePointUploader(
                site_url=ConstantesEspecificas.SHAREPOINT_BASE_URL,
                username=self.credenciais["sp_user"],
                password=self.credenciais["sp_password"]
            )
            
            # Prepara dados para upload
            data_str = data_referencia.strftime("%d.%m.%Y")
            nome_arquivo = f"C09 01 a {data_str}.xlsx"
            
            numero_mes = data_referencia.month
            nome_pasta_mes = f"{numero_mes:02d}. {ConstantesEspecificas.MESES_PT[numero_mes]}"
            ano_referencia = str(data_referencia.year)
            
            # Upload arquivo tratado
            sucesso_tratado = uploader.upload_arquivo(
                base_sharepoint=unidade_config["base_sharepoint"],
                ano=ano_referencia,
                mes=nome_pasta_mes,
                nome_arquivo=nome_arquivo,
                conteudo=buffer_tratado.read(),
                is_buffer=True
            )
            
            if not sucesso_tratado:
                return False
            
            # Upload arquivo original (se configurado)
            base_original = unidade_config["base_sharepoint"] + " Original"
            sucesso_original = uploader.upload_arquivo(
                base_sharepoint=base_original,
                ano=ano_referencia,
                mes=nome_pasta_mes,
                nome_arquivo=nome_arquivo,
                conteudo=caminho_original,
                is_buffer=False
            )
            
            return sucesso_tratado and sucesso_original
            
        except ImportError as e:
            print(f"‚ùå Erro de import no upload SharePoint: {e}")
            print("üîß Verifique se todos os m√≥dulos est√£o criados")
            return False
            
        except Exception as e:
            print(f"Erro no upload SharePoint: {e}")
            return False
    
    def _processar_analytics(self, unidade: str, buffer_tratado: BytesIO, data_referencia: datetime):
        """
        Executa processamento de analytics e alertas (modo completo).
        
        Args:
            unidade: Nome da unidade
            buffer_tratado: Buffer com dados tratados
            data_referencia: Data de refer√™ncia
        """
        try:
            print(f"Processando analytics para {unidade}...")
            
            from core.analytics_processor import criar_analytics_processor
            
            processor_analytics = criar_analytics_processor(
                unidade=unidade,
                config=self.config
            )
            
            sucesso = processor_analytics.processar_analytics_completo(
                buffer_dados=buffer_tratado,
                data_referencia=data_referencia
            )
            
            if not sucesso:
                print(f"‚ö†Ô∏è Analytics {unidade} processado com falhas")
            
        except ImportError as e:
            print(f"‚ùå Erro de import no analytics: {e}")
            print("üîß Verifique se todos os m√≥dulos est√£o criados")
            
        except Exception as e:
            print(f"‚ùå Erro no processamento de analytics {unidade}: {e}")
            # N√£o falha o processo principal se houver erro aqui
    
    def _limpar_arquivo_temporario(self, caminho_arquivo: str):
        """Remove arquivo tempor√°rio."""
        try:
            if os.path.exists(caminho_arquivo):
                os.remove(caminho_arquivo)
                print(f"Arquivo tempor√°rio removido: {Path(caminho_arquivo).name}")
        except Exception as e:
            print(f"Aviso: N√£o foi poss√≠vel remover arquivo tempor√°rio: {e}")
    
    def _log_erro_detalhado(self, erro: Exception, contexto: str):
        """
        Registra erro detalhado para debugging.
        
        Args:
            erro: Exception capturada
            contexto: Contexto onde ocorreu o erro
        """
        erro_detalhado = {
            "timestamp": datetime.now().isoformat(),
            "contexto": contexto,
            "erro": str(erro),
            "tipo": type(erro).__name__,
            "traceback": traceback.format_exc()
        }
        
        # Log para arquivo
        log_file = Path(__file__).parent / "logs" / "erros_detalhados.json"
        log_file.parent.mkdir(exist_ok=True)
        
        try:
            import json
            with open(log_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(erro_detalhado, ensure_ascii=False) + "\n")
        except:
            pass  # Se falhar o log, n√£o quebra o sistema
    
    def executar_com_retry(self, max_tentativas: int = 10) -> bool:
        """
        Executa ciclo com sistema de retry.
        
        Args:
            max_tentativas: M√°ximo de tentativas em caso de falha
            
        Returns:
            True se executado com sucesso
        """
        for tentativa in range(1, max_tentativas + 1):
            try:
                if self.modo_execucao == "CANDLES":
                    sucesso = self.executar_ciclo_candles()
                else:
                    sucesso = self.executar_ciclo_completo()
                
                if sucesso:
                    return True
                else:
                    print(f"‚ö†Ô∏è Tentativa {tentativa}/{max_tentativas} falhou")
                    
            except Exception as e:
                print(f"‚ùå Tentativa {tentativa}/{max_tentativas} - Erro: {e}")
                self._log_erro_detalhado(e, f"Tentativa {tentativa}")
                
                if tentativa == max_tentativas:
                    # √öltima tentativa - enviar e-mail de falha cr√≠tica
                    self._notificar_falha_critica(e, tentativa)
                    return False
                
                # Aguarda antes da pr√≥xima tentativa (backoff exponencial)
                import time
                time.sleep(min(60 * tentativa, 600))  # Max 10 min
        
        return False
    
    def executar_ciclo_candles(self) -> bool:
        """
        Executa ciclo r√°pido para todas as unidades (modo 10min).
        
        Returns:
            True se todas as unidades processadas com sucesso
        """
        unidades_ativas = [u for u in self.config["unidades"] if u.get("ativo", True)]
        
        print(f"üîÑ MODO CANDLES - Atualizando {len(unidades_ativas)} unidades...")
        
        sucessos = 0
        falhas = 0
        
        for unidade_config in unidades_ativas:
            sucesso = self.processar_unidade_modo_candles(unidade_config)
            
            if sucesso:
                sucessos += 1
            else:
                falhas += 1
        
        # Relat√≥rio resumido
        print(f"\nüìä CANDLES CONCLU√çDO: {sucessos}‚úÖ {falhas}‚ùå")
        return falhas == 0
    
    def executar_ciclo_completo(self) -> bool:
        """
        Executa ciclo completo para todas as unidades (modo 1h).
        
        Returns:
            True se todas as unidades processadas com sucesso
        """
        unidades_ativas = [u for u in self.config["unidades"] if u.get("ativo", True)]
        
        print(f"Iniciando processamento de {len(unidades_ativas)} unidades...")
        
        sucessos = 0
        falhas = 0
        
        for unidade_config in unidades_ativas:
            unidade = unidade_config["unidade"]
            print(f"\nüîÑ AGUARDANDO PROCESSAMENTO DE {unidade}...")
            print(f"‚è≥ Outras unidades aguardar√£o {unidade} terminar completamente")
            
            sucesso = self.processar_unidade_modo_completo(unidade_config)
            
            if sucesso:
                sucessos += 1
                print(f"‚úÖ {unidade} CONCLU√çDA - Pr√≥xima unidade pode iniciar")
            else:
                falhas += 1
                print(f"‚ùå {unidade} FALHADA - Continuando para pr√≥xima unidade")
            
            # Pausa entre unidades para garantir limpeza
            import time
            time.sleep(2)
        
        # Relat√≥rio final
        print(f"\n{'='*60}")
        print(f"RELAT√ìRIO FINAL")
        print(f"{'='*60}")
        print(f"‚úÖ Sucessos: {sucessos}")
        print(f"‚ùå Falhas: {falhas}")
        print(f"üìä Total: {len(unidades_ativas)}")
        
        if falhas > 0:
            print(f"\n‚ö†Ô∏è ATEN√á√ÉO: {falhas} unidade(s) falharam!")
            self._notificar_falhas(falhas)
        
        return falhas == 0
    
    def _notificar_falhas(self, num_falhas: int):
        """
        Notifica falhas por e-mail.
        
        Args:
            num_falhas: N√∫mero de falhas ocorridas
        """
        try:
            from core.email_notifier import EmailNotifier
            
            notifier = EmailNotifier(self.config)
            notifier.enviar_falha_sistema(
                erro=f"{num_falhas} unidade(s) falharam no processamento",
                contexto=f"Modo {self.modo_execucao}",
                timestamp=datetime.now()
            )
        except ImportError:
            print(f"‚ö†Ô∏è Sistema de e-mail n√£o implementado ainda")
        except Exception as e:
            print(f"‚ö†Ô∏è Falha ao enviar e-mail: {e}")
    
    def _notificar_falha_critica(self, erro: Exception, tentativas: int):
        """
        Notifica falha cr√≠tica ap√≥s esgotar tentativas.
        
        Args:
            erro: Exception que causou a falha
            tentativas: N√∫mero de tentativas realizadas
        """
        try:
            from core.email_notifier import EmailNotifier
            
            notifier = EmailNotifier(self.config)
            notifier.enviar_falha_critica(
                erro=erro,
                tentativas=tentativas,
                modo=self.modo_execucao,
                timestamp=datetime.now()
            )
        except ImportError:
            print(f"‚ö†Ô∏è Sistema de e-mail n√£o implementado ainda")
        except Exception as e:
            print(f"‚ö†Ô∏è Falha ao enviar e-mail cr√≠tico: {e}")


def main():
    """Fun√ß√£o principal - ponto de entrada do sistema."""
    
    # Configurar logging para arquivo
    log_file = Path(__file__).parent / "logs" / "execucao.log"
    log_file.parent.mkdir(exist_ok=True)
    
    try:
        # Redireciona stdout e stderr para arquivo de log
        with open(log_file, "a", encoding="utf-8") as f:
            # Mant√©m sa√≠da no console tamb√©m
            import sys
            
            class TeeOutput:
                def __init__(self, file, console):
                    self.file = file
                    self.console = console
                
                def write(self, data):
                    self.console.write(data)
                    self.file.write(data)
                    self.file.flush()
                
                def flush(self):
                    self.console.flush()
                    self.file.flush()
            
            # Escreve cabe√ßalho no log
            f.write(f"\n{'='*80}\n")
            f.write(f"EXECU√á√ÉO C09 - {datetime.now():%Y-%m-%d %H:%M:%S}\n")
            f.write(f"{'='*80}\n")
            f.flush()
            
            original_stdout = sys.stdout
            original_stderr = sys.stderr
            
            sys.stdout = TeeOutput(f, original_stdout)
            sys.stderr = TeeOutput(f, original_stderr)
            
            try:
                # Executa orquestrador com retry
                orchestrator = C09Orchestrator()
                sucesso = orchestrator.executar_com_retry(max_tentativas=10)
                
                if sucesso:
                    print(f"\nüéâ EXECU√á√ÉO CONCLU√çDA COM SUCESSO - {datetime.now():%H:%M:%S}")
                    sys.exit(0)
                else:
                    print(f"\nüí• EXECU√á√ÉO FINALIZADA COM FALHAS - {datetime.now():%H:%M:%S}")
                    sys.exit(1)
                    
            finally:
                # Restaura stdout/stderr originais
                sys.stdout = original_stdout
                sys.stderr = original_stderr
                
    except Exception as e:
        print(f"\nüí• ERRO CR√çTICO: {e}")
        traceback.print_exc()
        
        # Escreve erro no log tamb√©m
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(f"\nüí• ERRO CR√çTICO: {e}\n")
            traceback.print_exc(file=f)
        
        sys.exit(1)


if __name__ == "__main__":
    main()